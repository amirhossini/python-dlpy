

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>dlpy.applications.YoloV2_MultiSize &mdash; DLPy 1.2.1-dev documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="dlpy.applications.Tiny_YoloV1" href="dlpy.applications.Tiny_YoloV1.html" />
    <link rel="prev" title="dlpy.applications.YoloV2" href="dlpy.applications.YoloV2.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DLPy
          

          
          </a>

          
            
            
              <div class="version">
                1.2.1-dev
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../whatsnew.html">What’s New</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../building_models.html">Building Models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../api.html#imagetable">ImageTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#audiotable">AudioTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#timeseries">Timeseries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#layers">Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#solvers">Solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#optimizer">Optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#learning-rate-scheduler">Learning Rate Scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#metrics">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#feature-maps">Feature Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#sequential-model">Sequential Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#residual-networks">Residual Networks</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#pre-built-models-for-computer-vision-tasks">Pre-Built Models for Computer Vision Tasks</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../api.html#image-classification">Image Classification</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../api.html#object-detection">Object Detection</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="dlpy.applications.YoloV1.html">dlpy.applications.YoloV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="dlpy.applications.YoloV2.html">dlpy.applications.YoloV2</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">dlpy.applications.YoloV2_MultiSize</a></li>
<li class="toctree-l4"><a class="reference internal" href="dlpy.applications.Tiny_YoloV1.html">dlpy.applications.Tiny_YoloV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="dlpy.applications.Tiny_YoloV2.html">dlpy.applications.Tiny_YoloV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="dlpy.applications.Faster_RCNN.html">dlpy.applications.Faster_RCNN</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#image-captioning">Image Captioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#image-embedding">Image Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#pre-built-models-for-nlp-tasks">Pre-Built Models for NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#speech">Speech</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#speech-utilities">Speech Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#splitting-utilities">Splitting Utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DLPy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../api.html">API Reference</a> &raquo;</li>
        
      <li>dlpy.applications.YoloV2_MultiSize</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/generated/dlpy.applications.YoloV2_MultiSize.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dlpy-applications-yolov2-multisize">
<h1>dlpy.applications.YoloV2_MultiSize<a class="headerlink" href="#dlpy-applications-yolov2-multisize" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="dlpy.applications.YoloV2_MultiSize">
<code class="sig-prename descclassname">dlpy.applications.</code><code class="sig-name descname">YoloV2_MultiSize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">conn</span></em>, <em class="sig-param"><span class="n">anchors</span></em>, <em class="sig-param"><span class="n">model_table</span><span class="o">=</span><span class="default_value">'YoloV2-MultiSize'</span></em>, <em class="sig-param"><span class="n">n_channels</span><span class="o">=</span><span class="default_value">3</span></em>, <em class="sig-param"><span class="n">width</span><span class="o">=</span><span class="default_value">416</span></em>, <em class="sig-param"><span class="n">height</span><span class="o">=</span><span class="default_value">416</span></em>, <em class="sig-param"><span class="n">scale</span><span class="o">=</span><span class="default_value">0.00392156862745098</span></em>, <em class="sig-param"><span class="n">random_mutation</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">act</span><span class="o">=</span><span class="default_value">'leaky'</span></em>, <em class="sig-param"><span class="n">act_detection</span><span class="o">=</span><span class="default_value">'AUTO'</span></em>, <em class="sig-param"><span class="n">softmax_for_class_prob</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">coord_type</span><span class="o">=</span><span class="default_value">'YOLO'</span></em>, <em class="sig-param"><span class="n">max_label_per_image</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">max_boxes</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">n_classes</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">predictions_per_grid</span><span class="o">=</span><span class="default_value">5</span></em>, <em class="sig-param"><span class="n">do_sqrt</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">grid_number</span><span class="o">=</span><span class="default_value">13</span></em>, <em class="sig-param"><span class="n">coord_scale</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">object_scale</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">prediction_not_a_object_scale</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_scale</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">detection_threshold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iou_threshold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">random_boxes</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">match_anchor_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_to_force_coord</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">random_flip</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">random_crop</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#dlpy.applications.YoloV2_MultiSize" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a deep learning model with the Yolov2 architecture.</p>
<p>The model is same as Yolov2 proposed in original paper. In addition to
Yolov2, the model adds a passthrough layer that brings feature from an
earlier layer to lower resolution layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>conn</strong><span class="classifier">CAS</span></dt><dd><p>Specifies the connection of the CAS connection.</p>
</dd>
<dt><strong>anchors</strong><span class="classifier">list</span></dt><dd><p>Specifies the anchor box values.</p>
</dd>
<dt><strong>model_table</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies the name of CAS table to store the model.</p>
</dd>
<dt><strong>n_channels</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the number of the channels (i.e., depth) of the input layer.
Default: 3</p>
</dd>
<dt><strong>width</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the width of the input layer.
Default: 416</p>
</dd>
<dt><strong>height</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the height of the input layer.
Default: 416</p>
</dd>
<dt><strong>scale</strong><span class="classifier">double, optional</span></dt><dd><p>Specifies a scaling factor to be applied to each pixel intensity values.
Default: 1.0 / 255</p>
</dd>
<dt><strong>random_mutation</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies how to apply data augmentations/mutations to the data in the
input layer.
Valid Values: ‘none’, ‘random’</p>
</dd>
<dt><strong>act</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies the activation function for the batch normalization layers.
Default: ‘leaky’</p>
</dd>
<dt><strong>act_detection</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies the activation function for the detection layer.
Valid Values: AUTO, IDENTITY, LOGISTIC, SIGMOID, TANH, RECTIFIER, RELU, SOFPLUS, ELU, LEAKY, FCMP
Default: AUTO</p>
</dd>
<dt><strong>softmax_for_class_prob</strong><span class="classifier">bool, optional</span></dt><dd><p>Specifies whether to perform Softmax on class probability per
predicted object.
Default: True</p>
</dd>
<dt><strong>coord_type</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies the format of how to represent bounding boxes. For example,
a bounding box can be represented with the x and y locations of the
top-left point as well as width and height of the rectangle.
This format is the ‘rect’ format. We also support coco and yolo formats.
Valid Values: ‘rect’, ‘yolo’, ‘coco’
Default: ‘yolo’</p>
</dd>
<dt><strong>max_label_per_image</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the maximum number of labels per image in the training.
Default: 30</p>
</dd>
<dt><strong>max_boxes</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the maximum number of overall predictions allowed in the
detection layer.
Default: 30</p>
</dd>
<dt><strong>n_classes</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the number of classes. If None is assigned, the model will
automatically detect the number of classes based on the training set.
Default: 20</p>
</dd>
<dt><strong>predictions_per_grid</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the amount of predictions will be done per grid.
Default: 5</p>
</dd>
<dt><strong>do_sqrt</strong><span class="classifier">bool, optional</span></dt><dd><p>Specifies whether to apply the SQRT function to width and height of
the object for the cost function.
Default: True</p>
</dd>
<dt><strong>grid_number</strong><span class="classifier">int, optional</span></dt><dd><p>Specifies the amount of cells to be analyzed for an image. For example,
if the value is 5, then the image will be divided into a 5 x 5 grid.
Default: 13</p>
</dd>
<dt><strong>coord_scale</strong><span class="classifier">float, optional</span></dt><dd><p>Specifies the weight for the cost function in the detection layer,
when objects exist in the grid.</p>
</dd>
<dt><strong>object_scale</strong><span class="classifier">float, optional</span></dt><dd><p>Specifies the weight for object detected for the cost function in
the detection layer.</p>
</dd>
<dt><strong>prediction_not_a_object_scale</strong><span class="classifier">float, optional</span></dt><dd><p>Specifies the weight for the cost function in the detection layer,
when objects do not exist in the grid.</p>
</dd>
<dt><strong>class_scale</strong><span class="classifier">float, optional</span></dt><dd><p>Specifies the weight for the class of object detected for the cost
function in the detection layer.</p>
</dd>
<dt><strong>detection_threshold</strong><span class="classifier">float, optional</span></dt><dd><p>Specifies the threshold for object detection.</p>
</dd>
<dt><strong>iou_threshold</strong><span class="classifier">float, optional</span></dt><dd><p>Specifies the IOU Threshold of maximum suppression in object detection.</p>
</dd>
<dt><strong>random_boxes</strong><span class="classifier">bool, optional</span></dt><dd><p>Randomizing boxes when loading the bounding box information. Default: False</p>
</dd>
<dt><strong>match_anchor_size</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to force the predicted box match the anchor boxes in sizes for all predictions</p>
</dd>
<dt><strong>num_to_force_coord</strong><span class="classifier">int, optional</span></dt><dd><p>The number of leading chunk of images in training when the algorithm forces predicted objects
in each grid to be equal to the anchor box sizes, and located at the grid center</p>
</dd>
<dt><strong>random_flip</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies how to flip the data in the input layer when image data is
used. Approximately half of the input data is subject to flipping.
Valid Values: ‘h’, ‘hv’, ‘v’, ‘none’</p>
</dd>
<dt><strong>random_crop</strong><span class="classifier">string, optional</span></dt><dd><p>Specifies how to crop the data in the input layer when image data is
used. Images are cropped to the values that are specified in the width
and height parameters. Only the images with one or both dimensions
that are larger than those sizes are cropped.
Valid Values: ‘none’, ‘unique’, ‘randomresized’, ‘resizethencrop’</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">Sequential</span></code></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1612.08242.pdf">https://arxiv.org/pdf/1612.08242.pdf</a></p>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dlpy.applications.Tiny_YoloV1.html" class="btn btn-neutral float-right" title="dlpy.applications.Tiny_YoloV1" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="dlpy.applications.YoloV2.html" class="btn btn-neutral float-left" title="dlpy.applications.YoloV2" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018 SAS Institute Inc. All Rights Reserved.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>